{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GridSearchcv.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOlX2ykTad7gaqgOLqEa5Bb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82Nxxi4gEA5u","executionInfo":{"status":"ok","timestamp":1616351964784,"user_tz":-330,"elapsed":1162,"user":{"displayName":"Harshil Bhavsar","photoUrl":"","userId":"08920213964487412343"}},"outputId":"4db863c2-a290-42c9-94b0-c7c2c66c40dc"},"source":["from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","from sklearn.svm import SVC\n","from PIL import Image\n","\n","print(__doc__)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Automatically created module for IPython interactive environment\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xXG3nJ4qEF-c","executionInfo":{"status":"ok","timestamp":1616353148390,"user_tz":-330,"elapsed":1287,"user":{"displayName":"Harshil Bhavsar","photoUrl":"","userId":"08920213964487412343"}},"outputId":"bdc44d6c-97c5-4a13-e5fc-e17c253ba202"},"source":["# Loading the Digits dataset\n","digits = datasets.load_digits()\n","keys=[]\n","# keys = key for key in digits.keys()\n","# img=Image.fromarray(digits.images[0],mode=None)\n","for x in digits.keys():\n","  keys.append(x)\n","\n","\n","keys"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['data', 'target', 'target_names', 'images', 'DESCR']"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"rtqomjL0EYbs","executionInfo":{"status":"ok","timestamp":1616353238752,"user_tz":-330,"elapsed":1122,"user":{"displayName":"Harshil Bhavsar","photoUrl":"","userId":"08920213964487412343"}}},"source":["# To apply an classifier on this data, we need to flatten the image, to\n","# turn the data in a (samples, feature) matrix:\n","n_samples = len(digits.images)\n","X = digits.images.reshape((n_samples, -1))\n","y = digits.target\n"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"PO2j5fy3EYzN","executionInfo":{"status":"ok","timestamp":1616353292349,"user_tz":-330,"elapsed":1183,"user":{"displayName":"Harshil Bhavsar","photoUrl":"","userId":"08920213964487412343"}}},"source":["# Split the dataset in two equal parts\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.5, random_state=0)\n"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"TPeJi487EaUb","executionInfo":{"status":"ok","timestamp":1616353292801,"user_tz":-330,"elapsed":1334,"user":{"displayName":"Harshil Bhavsar","photoUrl":"","userId":"08920213964487412343"}}},"source":["# Set the parameters by cross-validation\n","tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n","                     'C': [1, 10, 100, 1000]},\n","                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n","\n","scores = ['precision', 'recall']\n"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4euBJ3EzEanq","executionInfo":{"status":"ok","timestamp":1616353422002,"user_tz":-330,"elapsed":6106,"user":{"displayName":"Harshil Bhavsar","photoUrl":"","userId":"08920213964487412343"}},"outputId":"9ea55144-ff0d-4a8b-819d-06b68dc2721a"},"source":["for score in scores:\n","    print(\"# Tuning hyper-parameters for %s\" % score)\n","    print()\n","\n","    clf = GridSearchCV(\n","        SVC(), tuned_parameters, scoring='%s_macro' % score\n","    )\n","    clf.fit(X_train, y_train)\n","\n","    print(\"Best parameters set found on development set:\")\n","    print()\n","    print(clf.best_params_)\n","    print()\n","    print(\"Grid scores on development set:\")\n","    print()\n","    means = clf.cv_results_['mean_test_score']\n","    stds = clf.cv_results_['std_test_score']\n","    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n","        print(\"%0.3f (+/-%0.03f) for %r\"\n","              % (mean, std * 2, params))\n","    print()\n","\n","    print(\"Detailed classification report:\")\n","    print()\n","    print(\"The model is trained on the full development set.\")\n","    print(\"The scores are computed on the full evaluation set.\")\n","    print()\n","    y_true, y_pred = y_test, clf.predict(X_test)\n","    print(classification_report(y_true, y_pred))\n","    print()\n","\n","# Note the problem is too easy: the hyperparameter plateau is too flat and the\n","# output model is the same for precision and recall with ties in quality."],"execution_count":31,"outputs":[{"output_type":"stream","text":["# Tuning hyper-parameters for precision\n","\n","Best parameters set found on development set:\n","\n","{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n","\n","Grid scores on development set:\n","\n","0.986 (+/-0.016) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.959 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.988 (+/-0.017) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.982 (+/-0.026) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.988 (+/-0.017) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.983 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.988 (+/-0.017) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.983 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.974 (+/-0.012) for {'C': 1, 'kernel': 'linear'}\n","0.974 (+/-0.012) for {'C': 10, 'kernel': 'linear'}\n","0.974 (+/-0.012) for {'C': 100, 'kernel': 'linear'}\n","0.974 (+/-0.012) for {'C': 1000, 'kernel': 'linear'}\n","\n","Detailed classification report:\n","\n","The model is trained on the full development set.\n","The scores are computed on the full evaluation set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        89\n","           1       0.97      1.00      0.98        90\n","           2       0.99      0.98      0.98        92\n","           3       1.00      0.99      0.99        93\n","           4       1.00      1.00      1.00        76\n","           5       0.99      0.98      0.99       108\n","           6       0.99      1.00      0.99        89\n","           7       0.99      1.00      0.99        78\n","           8       1.00      0.98      0.99        92\n","           9       0.99      0.99      0.99        92\n","\n","    accuracy                           0.99       899\n","   macro avg       0.99      0.99      0.99       899\n","weighted avg       0.99      0.99      0.99       899\n","\n","\n","# Tuning hyper-parameters for recall\n","\n","Best parameters set found on development set:\n","\n","{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n","\n","Grid scores on development set:\n","\n","0.986 (+/-0.019) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.957 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.987 (+/-0.019) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.981 (+/-0.028) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.987 (+/-0.019) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.982 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.987 (+/-0.019) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.982 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.971 (+/-0.010) for {'C': 1, 'kernel': 'linear'}\n","0.971 (+/-0.010) for {'C': 10, 'kernel': 'linear'}\n","0.971 (+/-0.010) for {'C': 100, 'kernel': 'linear'}\n","0.971 (+/-0.010) for {'C': 1000, 'kernel': 'linear'}\n","\n","Detailed classification report:\n","\n","The model is trained on the full development set.\n","The scores are computed on the full evaluation set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        89\n","           1       0.97      1.00      0.98        90\n","           2       0.99      0.98      0.98        92\n","           3       1.00      0.99      0.99        93\n","           4       1.00      1.00      1.00        76\n","           5       0.99      0.98      0.99       108\n","           6       0.99      1.00      0.99        89\n","           7       0.99      1.00      0.99        78\n","           8       1.00      0.98      0.99        92\n","           9       0.99      0.99      0.99        92\n","\n","    accuracy                           0.99       899\n","   macro avg       0.99      0.99      0.99       899\n","weighted avg       0.99      0.99      0.99       899\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zfj1C6P1EatO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k8o8OoGYEax_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCFjkWplEa0w"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YT7RstwJEa4r"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttfYMp-QEa7n"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nXlTF4j7Ea_M"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"32Z26vtCEbCZ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9493tsXGEbFP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8DilfbeWEbH7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jx3may4_EbK6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2TDQB-ZEbPD"},"source":[""],"execution_count":null,"outputs":[]}]}