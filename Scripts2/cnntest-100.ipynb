{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import SGD,Adam,RMSprop\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#cifar100 is a set of This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_CHANNELS=3\n",
    "IMG_ROWS=32\n",
    "IMG_COLS=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANT\n",
    "BATCH_SIZE=128\n",
    "NB_EPOCH=30\n",
    "NB_CLASSES=20\n",
    "VERBOSE=1\n",
    "VALIDATION_SPLIT=0.2\n",
    "OPTIM = RMSprop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (50000, 32, 32, 3)\n",
      "50000 train samples \n",
      "10000 train samples \n"
     ]
    }
   ],
   "source": [
    "# LOAD DATASET\n",
    "(X_train,y_train),(X_test,y_test)=cifar100.load_data()\n",
    "print('X_train shape ',X_train.shape)\n",
    "print(X_train.shape[0],'train samples ')\n",
    "print(X_test.shape[0],'train samples ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train,NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test,NB_CLASSES)\n",
    "# print('Y_train',Y_train)\n",
    "# print('Y_test',Y_test)\n",
    "\n",
    "# float and normalization\n",
    "X_train=X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# print('X_train',X_train)\n",
    "# print('X_test',X_test)\n",
    "X_train /= 255\n",
    "X_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),padding='same',\n",
    "                input_shape=(IMG_ROWS,IMG_COLS,IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 4,247,012\n",
      "Trainable params: 4,247,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "40000/40000 [==============================] - 176s 4ms/step - loss: 4.2584 - acc: 0.0566 - val_loss: 3.8058 - val_acc: 0.1244\n",
      "Epoch 2/30\n",
      "40000/40000 [==============================] - 165s 4ms/step - loss: 3.7124 - acc: 0.1343 - val_loss: 3.4244 - val_acc: 0.1899\n",
      "Epoch 3/30\n",
      "40000/40000 [==============================] - 165s 4ms/step - loss: 3.4326 - acc: 0.1824 - val_loss: 3.2304 - val_acc: 0.2222\n",
      "Epoch 4/30\n",
      "40000/40000 [==============================] - 167s 4ms/step - loss: 3.2567 - acc: 0.2146 - val_loss: 3.1351 - val_acc: 0.2466\n",
      "Epoch 5/30\n",
      "40000/40000 [==============================] - 165s 4ms/step - loss: 3.1302 - acc: 0.2359 - val_loss: 3.0109 - val_acc: 0.2689\n",
      "Epoch 6/30\n",
      "40000/40000 [==============================] - 167s 4ms/step - loss: 3.0234 - acc: 0.2541 - val_loss: 2.9356 - val_acc: 0.2803\n",
      "Epoch 7/30\n",
      "40000/40000 [==============================] - 166s 4ms/step - loss: 2.9445 - acc: 0.2741 - val_loss: 2.8980 - val_acc: 0.2882\n",
      "Epoch 8/30\n",
      "40000/40000 [==============================] - 2058s 51ms/step - loss: 2.8704 - acc: 0.2875 - val_loss: 2.8770 - val_acc: 0.2922\n",
      "Epoch 9/30\n",
      "40000/40000 [==============================] - 150s 4ms/step - loss: 2.8009 - acc: 0.2997 - val_loss: 2.7852 - val_acc: 0.3117\n",
      "Epoch 10/30\n",
      "40000/40000 [==============================] - 167s 4ms/step - loss: 2.7390 - acc: 0.3108 - val_loss: 2.7912 - val_acc: 0.3126\n",
      "Epoch 11/30\n",
      "40000/40000 [==============================] - 166s 4ms/step - loss: 2.6728 - acc: 0.3240 - val_loss: 2.8279 - val_acc: 0.3071\n",
      "Epoch 12/30\n",
      "40000/40000 [==============================] - 164s 4ms/step - loss: 2.6196 - acc: 0.3348 - val_loss: 2.7653 - val_acc: 0.3192\n",
      "Epoch 13/30\n",
      "40000/40000 [==============================] - 165s 4ms/step - loss: 2.5686 - acc: 0.3443 - val_loss: 2.7214 - val_acc: 0.3261\n",
      "Epoch 14/30\n",
      "40000/40000 [==============================] - 163s 4ms/step - loss: 2.5146 - acc: 0.3557 - val_loss: 2.7327 - val_acc: 0.3269\n",
      "Epoch 15/30\n",
      "40000/40000 [==============================] - 165s 4ms/step - loss: 2.4739 - acc: 0.3627 - val_loss: 2.7790 - val_acc: 0.3180\n",
      "Epoch 16/30\n",
      "40000/40000 [==============================] - 165s 4ms/step - loss: 2.4300 - acc: 0.3693 - val_loss: 2.8026 - val_acc: 0.3150\n",
      "Epoch 17/30\n",
      "40000/40000 [==============================] - 164s 4ms/step - loss: 2.3863 - acc: 0.3806 - val_loss: 2.7120 - val_acc: 0.3322\n",
      "Epoch 18/30\n",
      "40000/40000 [==============================] - 165s 4ms/step - loss: 2.3502 - acc: 0.3886 - val_loss: 2.6853 - val_acc: 0.3336\n",
      "Epoch 19/30\n",
      "40000/40000 [==============================] - 165s 4ms/step - loss: 2.3006 - acc: 0.3980 - val_loss: 2.8054 - val_acc: 0.3240\n",
      "Epoch 20/30\n",
      "40000/40000 [==============================] - 168s 4ms/step - loss: 2.2812 - acc: 0.4001 - val_loss: 2.7084 - val_acc: 0.3350\n",
      "Epoch 21/30\n",
      "40000/40000 [==============================] - 166s 4ms/step - loss: 2.2235 - acc: 0.4149 - val_loss: 2.6859 - val_acc: 0.3384\n",
      "Epoch 22/30\n",
      "40000/40000 [==============================] - 297s 7ms/step - loss: 2.2017 - acc: 0.4191 - val_loss: 2.7580 - val_acc: 0.3368\n",
      "Epoch 23/30\n",
      "40000/40000 [==============================] - 131s 3ms/step - loss: 2.1826 - acc: 0.4220 - val_loss: 2.7610 - val_acc: 0.3377\n",
      "Epoch 24/30\n",
      "40000/40000 [==============================] - 165s 4ms/step - loss: 2.1391 - acc: 0.4315 - val_loss: 2.7938 - val_acc: 0.3399\n",
      "Epoch 25/30\n",
      "40000/40000 [==============================] - 168s 4ms/step - loss: 2.0991 - acc: 0.4387 - val_loss: 2.7425 - val_acc: 0.3450\n",
      "Epoch 26/30\n",
      "40000/40000 [==============================] - 166s 4ms/step - loss: 2.0497 - acc: 0.4511 - val_loss: 2.7529 - val_acc: 0.3466\n",
      "Epoch 27/30\n",
      "40000/40000 [==============================] - 166s 4ms/step - loss: 2.0261 - acc: 0.4562 - val_loss: 2.7662 - val_acc: 0.3396\n",
      "Epoch 28/30\n",
      "40000/40000 [==============================] - 166s 4ms/step - loss: 2.0017 - acc: 0.4612 - val_loss: 2.7499 - val_acc: 0.3349\n",
      "Epoch 29/30\n",
      "40000/40000 [==============================] - 166s 4ms/step - loss: 1.9771 - acc: 0.4700 - val_loss: 2.9124 - val_acc: 0.2999\n",
      "Epoch 30/30\n",
      "40000/40000 [==============================] - 165s 4ms/step - loss: 1.9559 - acc: 0.4708 - val_loss: 2.8354 - val_acc: 0.3336\n",
      "10000/10000 [==============================] - 17s 2ms/step\n",
      "Test score:  2.8271183570861815\n",
      "Test Accuracy 0.3433\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "model.compile(loss='categorical_crossentropy',optimizer = OPTIM,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,batch_size=BATCH_SIZE,\n",
    "         epochs=NB_EPOCH,validation_split=VALIDATION_SPLIT,\n",
    "         verbose=VERBOSE)\n",
    "score=model.evaluate(X_test,Y_test,\n",
    "                    batch_size=BATCH_SIZE,verbose = VERBOSE)\n",
    "\n",
    "print(\"Test score: \",score[0])\n",
    "print(\"Test Accuracy\",score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names=['cat.png','dog.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = Image.open(r'C:\\Users\\Harshil\\Desktop\\Black-Cat-icon.png')\n",
    "# print(im)\n",
    "# print(im.shape)\n",
    "# size=(32,32)\n",
    "# out = im.resize(size)\n",
    "# # out.save('resize-output.png')\n",
    "# out=np.array(out)\n",
    "# print(out)\n",
    "# print(out.shape)\n",
    "# print(type(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.misc.imread('Black-Cat-icon.jpg')\n",
    "# import imageio\n",
    "# im = imageio.imread('Black-Cat-icon.png')\n",
    "# print(type(im))\n",
    "# im.shape(32,32,3)  # im is a numpy array\n",
    "# imageio.imwrite('imageio:cat-gray.jpg', im[:, :, 0])\n",
    "# imgs=plt.imread('Black-Cat-icon.png')\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "imgs = PIL.Image.open('frog1.png')\n",
    "imgs = imgs.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=1160x600 at 0x160AE366710>\n"
     ]
    }
   ],
   "source": [
    "print(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "(600, 1160, 3)\n"
     ]
    }
   ],
   "source": [
    "print(type(imgs))\n",
    "imgs=np.array(imgs)\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=np.resize(imgs,(32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=np.reshape(imgs,(1,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(imgs.reshape(1,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
